{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMb+CXZ8oHDvWHFMBwesEmQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarvAster/GNN-KN-TRANSFORMER/blob/main/GNN_cheatsheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Feature**                 | **NetworkX Function**                   | **PyTorch Geometric Equivalent**               |\n",
        "|-----------------------------|------------------------------------------|-----------------------------------------------|\n",
        "| **Number of Nodes**         | `G.number_of_nodes()`                   | `data.num_nodes`                              |\n",
        "| **Number of Edges**         | `G.number_of_edges()`                   | `data.num_edges`                              |\n",
        "| **Node List**               | `list(G.nodes)`                         | `data.x` (if node features exist)             |\n",
        "| **Edge List**               | `list(G.edges)`                         | `data.edge_index`                             |\n",
        "| **Check Directed**          | `G.is_directed()`                       | `data.is_directed()` (if attribute exists)    |\n",
        "| **Node Attributes**         | `G.nodes[node]['attr']`                 | `data.x` (contains features for nodes)        |\n",
        "| **Edge Attributes**         | `G.edges[u, v]['attr']`                 | `data.edge_attr` (if edge features exist)     |\n",
        "| **Neighbors of Node**       | `list(G.neighbors(node))`               | Not directly supported; use `edge_index`      |\n",
        "| **Graph Degree**            | `G.degree[node]`                        | Compute manually using `torch_geometric.utils.degree(data.edge_index[0])` |\n",
        "| **Graph Density**           | `nx.density(G)`                         | Compute manually using `2 * num_edges / (num_nodes * (num_nodes - 1))` |\n",
        "| **Subgraph**                | `G.subgraph(nodes)`                     | Slice `data` manually to create subgraph      |\n",
        "| **Graph Adjacency Matrix**  | `nx.adjacency_matrix(G)`                | `torch_geometric.utils.to_scipy_sparse_matrix(data.edge_index)` |\n",
        "| **Graph Clustering Coefficient** | `nx.clustering(G)`                  | Not directly available                        |\n",
        "| **Convert Graph to Edge List** | `list(G.edges)`                      | `data.edge_index`                             |\n",
        "| **Add Node**                | `G.add_node(node, attr=val)`            | Modify `data.x` manually                      |\n",
        "| **Add Edge**                | `G.add_edge(u, v, attr=val)`            | Modify `data.edge_index` and `data.edge_attr` manually |\n",
        "| **Remove Node**             | `G.remove_node(node)`                   | Modify `data.x` and `data.edge_index` manually |\n",
        "| **Remove Edge**             | `G.remove_edge(u, v)`                   | Modify `data.edge_index` manually             |\n",
        "| **Convert to PyTorch Geometric** | `from_networkx(G)`                 | `torch_geometric.utils.from_networkx(G)`      |\n",
        "| **Convert to NetworkX**     | `G = nx.from_scipy_sparse_matrix(adj_matrix)` | `torch_geometric.utils.to_networkx(data)`    |\n",
        "| **Import a Dataset**        | Use custom loading logic                | Use a PyG dataset loader, e.g., `TUDataset` or `Planetoid` |\n",
        "| **Number of Graphs in Dataset** | `len(graph_list)`                    | `len(dataset)`                                |\n",
        "| **Number of Features**      | N/A                                     | `dataset.num_node_features`                  |\n",
        "| **Number of Classes**       | N/A                                     | `dataset.num_classes`                        |\n",
        "| **Dataset Summary**         | Manual iteration over graphs            | `print(dataset)`                              |\n",
        "| **Graph Labels**            | Iterate through graph attributes        | Access via `data.y` (graph or node labels)    |\n",
        "| **Node Labels**             | Iterate through node attributes         | `data.y` (for node-level tasks)               |\n",
        "| **Edge Features**           | Iterate through edge attributes         | `data.edge_attr`                              |\n",
        "| **Inspect Individual Graph** | `graph_list[i]`                        | `dataset[i]`                                  |\n",
        "| **Node Features of Graph**  | `G.nodes(data=True)`                    | `data.x`                                      |\n",
        "| **Class Distribution**      | Custom aggregation logic                | Use `torch.bincount(dataset.data.y)`          |\n",
        "\n"
      ],
      "metadata": {
        "id": "3moCxPMR--sd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Embedding Methods\n",
        "\n",
        "## 1. Classical Graph Embedding Methods\n",
        "\n",
        "### (a) Matrix Factorization-Based Methods\n",
        "1. **Laplacian Eigenmaps**\n",
        "   - Uses the graph Laplacian matrix to generate embeddings.\n",
        "   - Preserves local structure by minimizing the distances between neighboring nodes in the embedding space.\n",
        "   - **Limitation**: Computationally expensive and scales poorly to large graphs.\n",
        "\n",
        "2. **Graph Factorization**\n",
        "   - Factorizes the adjacency matrix or other graph-derived matrices.\n",
        "   - Example: Singular Value Decomposition (SVD) on the adjacency matrix.\n",
        "\n",
        "3. **HOPE (High-Order Proximity Embedding)**\n",
        "   - Captures higher-order proximities (e.g., Katz index, Personalized PageRank) using matrix factorization.\n",
        "\n",
        "### (b) Random Walk-Based Methods\n",
        "1. **DeepWalk**\n",
        "   - Simulates random walks on the graph to generate sequences of nodes.\n",
        "   - Treats these sequences like sentences and uses the Skip-gram model (from Word2Vec) to generate embeddings.\n",
        "   - Captures neighborhood similarity and community structure.\n",
        "\n",
        "2. **Node2Vec**\n",
        "   - Extends DeepWalk by introducing a bias in the random walks:\n",
        "     - Breadth-First Search (BFS) bias: Focuses on capturing structural roles.\n",
        "     - Depth-First Search (DFS) bias: Focuses on capturing neighborhood similarity.\n",
        "   - Balances between capturing local and global graph structure.\n",
        "\n",
        "3. **Walklets**\n",
        "   - Similar to DeepWalk but skips intermediate nodes in random walks to capture higher-order relationships.\n",
        "\n",
        "### (c) Factorization of Graph Kernels\n",
        "1. **Weisfeiler-Lehman Kernel**\n",
        "   - Encodes node neighborhoods iteratively and uses kernel methods for embedding.\n",
        "\n",
        "2. **Shortest Path Kernel**\n",
        "   - Embeds graphs by comparing all pairs of shortest paths.\n",
        "\n",
        "3. **Graphlet Kernel**\n",
        "   - Embeds graphs by counting small induced subgraphs (graphlets).\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Deep Learning-Based Graph Embedding Methods\n",
        "\n",
        "### (a) Graph Neural Networks (GNNs)\n",
        "1. **GCN (Graph Convolutional Networks)**\n",
        "   - Aggregates features from neighbors through a convolution-like operation.\n",
        "   - **Embedding formula**:  \n",
        "     \\[\n",
        "     H^{(l+1)} = \\sigma(D^{-1/2} A D^{-1/2} H^{(l)} W^{(l)})\n",
        "     \\]\n",
        "     - \\( A \\): Normalized adjacency matrix.\n",
        "     - \\( H^{(l)} \\): Node features at layer \\( l \\).\n",
        "   - Suitable for semi-supervised learning tasks.\n",
        "\n",
        "2. **GraphSAGE (Graph Sample and Aggregate)**\n",
        "   - Aggregates features from a sampled set of neighbors to handle large-scale graphs.\n",
        "   - Supports inductive learning (generalizes to unseen nodes).\n",
        "\n",
        "3. **GAT (Graph Attention Networks)**\n",
        "   - Introduces attention mechanisms to learn the importance of neighbors dynamically.\n",
        "   - **Embedding formula**:  \n",
        "     \\[\n",
        "     h_i^{(l+1)} = \\sigma\\left(\\sum_{j \\in N(i)} \\alpha_{ij} W^{(l)} h_j^{(l)}\\right)\n",
        "     \\]\n",
        "     - \\( \\alpha_{ij} \\): Attention coefficient between node \\( i \\) and \\( j \\).\n",
        "\n",
        "### (b) Variational Graph Embedding\n",
        "1. **VGAE (Variational Graph Autoencoders)**\n",
        "   - Extends autoencoders to graphs using graph convolution for encoding.\n",
        "   - Learns node embeddings and reconstructs the graph.\n",
        "\n",
        "2. **ARGA (Adversarially Regularized Graph Autoencoders)**\n",
        "   - Adds an adversarial training setup to regularize embeddings.\n",
        "\n",
        "### (c) Graph Embedding for Edges or Subgraphs\n",
        "1. **LINE (Large-Scale Information Network Embedding)**\n",
        "   - Optimizes edge similarity directly.\n",
        "   - Captures both first-order and second-order proximities.\n",
        "\n",
        "2. **Graph2Vec**\n",
        "   - Extends Doc2Vec for embedding entire subgraphs or graphs.\n",
        "   - Useful for graph classification tasks.\n",
        "\n",
        "### (d) Graph Representation Learning via Self-Supervised Learning\n",
        "1. **DGI (Deep Graph Infomax)**\n",
        "   - A self-supervised approach that maximizes mutual information between global graph representations and local node embeddings.\n",
        "\n",
        "2. **GRACE**\n",
        "   - Uses contrastive learning to maximize agreement between different augmented views of the graph.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Other Specialized Methods\n",
        "\n",
        "### Graph Embedding with Node Features\n",
        "1. **TGN (Temporal Graph Networks)**\n",
        "   - Captures dynamic node embeddings in temporal graphs.\n",
        "\n",
        "2. **Heterogeneous Graph Embedding**\n",
        "   - Methods like **HAN (Heterogeneous Attention Network)** deal with graphs containing different types of nodes and edges.\n"
      ],
      "metadata": {
        "id": "25lKCw0Ey7ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "G = nx.karate_club_graph()"
      ],
      "metadata": {
        "id": "MCerg4qU_HGG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}